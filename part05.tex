\section{Хеширование}
Прямая адресация.
Коллизии.
Разрешение коллизий методом цепочек,
методом последовательных проб и методом двойного хеширования.
Гипотеза равномерного хеширования.
Оценка времени поиска в хеш-таблице при
использовании метода цепочек для гипотезы
равномерного хеширования.
Примеры хеш-функций.

\subsection{Хеш-таблица}
Прямая адресация --- ключи сами являются целыми числами
из ограниченного диапазона $[0; m - 1]$, и $m$ небольшое.
Множество --- просто массив битов,
словарь --- массив ссылок (или объектов)
и специальных нулевых значений.

Хотим, чтобы размер таблицы был $\O(n)$,
где $n$ --- количество ключей.

Хеш-функция --- из множества ключей в
конечное множество индексов $h: K \to \{0, \ldots, m - 1\}$.
$h(k)$ --- хеш-код ключа $k$.
Поскольку хеш-кодов меньше, чем ключей,
то возникают \emph{коллизии}
--- когда $h(k_1) = h(k_2)$, но $k_1 \ne k_2$.
Коллизии неизбежны, и их обработка --- \emph{разрешение коллизий}.

\bigskip

Метод цепочек: в каждой ячейке (,,бакете``) хеш-таблицы
хранится список ключей с таким хеш-кодом.
Время добавления, удаления, поиска --- $\O(l)$,
где $l$ --- количество ключей в ячейке,
поэтому хотим как можно меньше коллизий.

\bigskip

Открытая адресация (метод последовательных проб):
ключу соответствует не ячейка,
а последовательность ячеек, получаемая как
\[ h(k, 0), h(k, 1), \ldots, h(k, m - 1) \]

При удалении нужно хранить в ячейке флаг, что значение было удалено.
Самый простой вариант новой хеш-функции:
\[ h(k, i) = (h(k) + i) \Mod m \]
Но тут цепочки близких ячеек таблицы ,,склеиваются``.

Более сложный --- \emph{двойное хеширование}:
\[ h(k, i) = (h_1(k) + i \cdot h_2(k)) \Mod m \]
Нужно обеспечить, чтобы для фиксированного ключа элементы
последовательности не повторялись.
Для этого $m$ можно выбрать простым,
тогда подойдёт любая $h_2 : K \to [1; m - 1]$ (не с 0!).

\subsection{Примеры хеш-функций}
Равномерно распределённые вещественные числа на $[0; 1)$:
\[ h(k) = \floor{mk} \]

Целые числа:
\[ h(k) = k \Mod m \]

Более качественное перемешивание целых чисел
--- мультипликативный метод:
\[ h(k) = \floor{m \cdot \{ck\}} \]
где $\{x\} = x - \floor{x}$, $c$ --- некоторая вещественная константа,
в идеале --- иррациональная, например, $\sqrt{2}$ или $\pi$.
Можно обобщить этот метод на пару:
\[ h(k_1, k_2) = \floor{m \cdot \{c_1 k_1 + c_2 k_2\}} \]
при этом $c_1$ и $c_2$ стоит выбирать линейно независимыми
над $\mathds{Q}$, например, $\sqrt{2}$ и $\sqrt{3}$.

Последовательности целых чисел (например, строки)
--- полиномиальный метод:
\[ h(a) = (a_0 + a_1 x + \ldots + a_n x^n) \Mod m \]
где $x$ --- некоторое взаимнопростое с $m$ число.

Кортежи разнотипных значений --- посчитать хеши
отдельных значений, дальше скомбинировать
полиномиальным или мультипликативным методом.

\subsection{Гипотеза равномерного хеширования}
Коэффициент заполнения таблицы $\alpha = n/m$.
Для любой хеш-функции можно подобрать набор ключей
с большим количеством коллизий.

\emph{Гипотеза равномерного хеширования}:
хеш-коды равномерно распределены на
множестве $\{0, \ldots, m - 1\}$,
а хеш-коды разных ключей независимы.

\begin{theorem}
    В предположении гипотезы равномерного хеширования
    среднее время безуспешного поиска в методе цепочек
    --- $\Theta(1 + \alpha)$.
\end{theorem}
\begin{proof}
    Мы должны полностью просмотреть ячейку по хеш-коду $h(k)$.
    Обозначим длину $i$-й цепочки как $l(i)$.
    Тогда математическое ожидание длины цепочки
    \[ l(h(k)) = \frac{1}{m} \sum_{i=0}^{m-1} l(i) = \frac{n}{m} = \alpha \]

    Мы всегда делаем хотя бы одну операцию, отсюда берётся 1.
    Поэтому $\Theta(1 + \alpha)$.
\end{proof}


\begin{theorem}
    В предположении гипотезы равномерного хеширования
    среднее время успешного поиска в методе цепочек
    --- $\Theta(1 + \alpha)$.
\end{theorem}
\begin{proof}
    Пусть были добавлены ключи $k_1, \ldots, k_n$
    в таком порядке.
    Пусть
    \[
        X(i, j) =
        \begin{cases}
            1 & h(k_i) = h(k_j) \\
            0 & h(k_i) \ne h(k_j) \\
        \end{cases}
    \]
    По гипотезе равномерного хеширования
    $\E[X(i, j)] = 1/m$ для $i \ne j$.

    Предположим, что ищем ключ $k_i$.
    Пусть элемент в ячейку добавляется в начало списка
    (т.е. становится головой односвязного).
    Тогда количество элементов,
    которые будут просмотрены,
    равно $X(i, i) + X(i, i + 1) + \ldots + X(i, n)$.

    Тогда среднее время по всем $i$ и по
    распределению $X(i, j)$:

    \begin{gather*}
        \frac{1}{n} \sum_{i=1}^n \E \brackets{\sum_{j=i}^n X(i, j)}
        = \frac{1}{n} \sum_{i=1}^n \parens{1 + \sum_{j = i + 1}^n \E X(i, j)} = \\
        = 1 + \frac{1}{n} \sum_{i=1}^n \sum_{j = i + 1}^n \frac{1}{m}
        = 1 + \frac{1}{n} \sum_{i=1}^n \frac{n - i}{m} = \\
        = 1 + \frac{1}{mn} \parens{n^2 - \frac{n (n + 1)}{2}}
        = 1 + \frac{1}{mn} \parens{n^2 - \frac{n (n + 1)}{2}} = \\
        = 1 + \frac{1}{2mn} \parens{n^2 - n}
        = 1 + \frac{n}{2m} - \frac{1}{2m} \in \Theta(1 + \alpha) \\
    \end{gather*}
\end{proof}
